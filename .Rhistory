<<<<<<< HEAD
138/11034
-.003/sqrt(0.01531213 * (1 - 0.01531213)/11037 + 0.0125068 * (1 - 0.0125068)/11034)
x = matrix(1:1000, nrow = 10)
t(x)
x $*$ t(x)
x %*% t(x)
eigen(x %*% t(x))
eigen(x %*% t(x))$values
eigen(x[,1:10] %*% t(x[,1:10]))$values
x[1:10]
x[,1:10]
x = matrix(1:100, nrow = 4)
eigen(x %*% t(x))$value
knitr::opts_chunk$set(echo = TRUE)
x = matrix(1:10, nrow = 2)
x[,1:2]
x
eigen(x%*%t(x))
eigen(x%*%t(x))$vectors
U = eigen(x%*%t(x))$vectors
U %*% t(U)
x = matrix(1:100, nrow = 20)
U $*$ t(U)
U %*% t(U)
x = matrix(1:100, nrow = 20)
U = eigen(x%*%t(x))$vectors
U %*% t(U)
x = matrix(1:100, nrow = 10)
x = matrix(1:100, nrow = 10)
U = eigen(x%*%t(x))$vectors
U %*% t(U)
eigen(U %*% t(U))
eigen(U %*% matrix(c(1, rep(0, 9), 0, 1, rep(0, 8), rep(0, 80)), nrow = 10) %*% t(U))
U %*% matrix(c(1, rep(0, 9), 0, 1, rep(0, 8), rep(0, 80)), nrow = 10) %*% t(U)
U %*% matrix(c(1, rep(0, 9), 0, 1, rep(0, 8), rep(0, 80)), nrow = 10) %*% t(U)
U[,1:2] %*% t(U[,1:2])
U[,1:2] %*% t(U[,1:2]) == U %*% matrix(c(1, rep(0, 9), 0, 1, rep(0, 8), rep(0, 80)), nrow = 10) %*% t(U)
eigen(U)
knitr::opts_chunk$set(echo = TRUE)
avg_poor = rep(0, 1601 + 2116)
not_poor = rep(1, 2318 + 136)
t.test(c(avg_poor, not_poor))
avg_poor = rep(0, 1601 + 2116)
not_poor = rep(1, 2318 + 136)
treatment = c(avg_poor, not_poor)
avg_poor_control = rep(0, 1665 + 2983)
not_poor_control = rep(1, 1186 + 92)
control = c(avg_poor_control, not_poor_control)
outcomes = c(treatment, control)
labels = c(rep(1, length(treatment)), rep(0, length(control)))
t.test(outcome ~ label)
avg_poor = rep(0, 1601 + 2116)
not_poor = rep(1, 2318 + 136)
treatment = c(avg_poor, not_poor)
avg_poor_control = rep(0, 1665 + 2983)
not_poor_control = rep(1, 1186 + 92)
control = c(avg_poor_control, not_poor_control)
outcomes = c(treatment, control)
labels = c(rep(1, length(treatment)), rep(0, length(control)))
t.test(outcomes ~ label)
avg_poor = rep(0, 1601 + 2116)
not_poor = rep(1, 2318 + 136)
treatment = c(avg_poor, not_poor)
avg_poor_control = rep(0, 1665 + 2983)
not_poor_control = rep(1, 1186 + 92)
control = c(avg_poor_control, not_poor_control)
outcomes = c(treatment, control)
labels = c(rep(1, length(treatment)), rep(0, length(control)))
t.test(outcomes ~ labels)
t.test(outcomes ~ labels, alternative = "greater")
t.test(outcomes ~ labels, alternative = "lesser")
t.test(outcomes ~ labels, alternative = "less")
t.test(outcomes ~ labels, alternative = "two.sided")
t.test(treatment)
t.test(control)
R.home()
install.packages("lme4")
install.packages("lme4")
install.packages("lme4")
install.packages("magrittr")
install.packages("readr")
rtime
library(lme4)
library(readr)
library(magrittr)
testdata <- read_csv("lmm_data.csv")
install.packages("Matrix")
install.packages("Matrix")
library(installr)
install.packages("installr")
library(installr)
updateR()
install.packages("lme4")
library(lme4)
library(readr)
library(magrittr)
testdata <- read_csv("lmm_data.csv")
install.packages("Matrix")
library(lme4)
install.packages("lme4")
install.packages("magrittr")
install.packages("readr")
R.home()
knitr::opts_chunk$set(echo = TRUE)
# Obtain the 2nd and 5th item in a vector
example_nums[c(2, 5)]
example_nums = 1:10
example_nums
# Obtain the 2nd and 5th item in a vector
example_nums[c(2, 5)]
knitr::opts_chunk$set(echo = TRUE)
nums = 1:100
nums[10]
nums2 = -10:10
nums2 = -10:10
nums2[c(3, 4, 5)]
nums2[nums2 < 0]
getwd()
AgeBMI = read.table("AgeBMI.txt", header = TRUE)
head(AgeBMI)
age = AgeBMI$Age
bmi = AgeBMI$BMI
mean(bmi)
age = AgeBMI$Age
bmi = AgeBMI$bmi
mean(bmi)
bmi_under_29 = bmi < 29
table(bmi_under_29)
knitr::opts_chunk$set(echo = TRUE)
# This makes sure that the random number generator produces the same outcome each time
set.seed(123)
num_samples = 100
# The number of people who have contracted chicken pox from a single sample of 100 people where the true probability of success is 0.85.
num_contracted = rbinom(1, num_samples, prob = 0.85)
num_contracted
# Fill in the following three variables based on the information given in the question
observed = 87/num_samples
expected = .9
SE = sqrt(.9 * (1 - .9)/num_samples)
# Code for calculation of z and one sided p value
z = (observed - expected)/SE
pval = pnorm(z)
# Print p value
pval
# This makes sure that the random number generator produces the same outcome each time
set.seed(123)
num_samples = 1000
# The number of people who have contracted chicken pox from a single sample of 100 people where the true probability of success is 0.85.
num_contracted = rbinom(1, num_samples, prob = 0.85)
num_contracted
# Fill in the following three variables based on the information given in the question
observed = 856/num_samples
expected = .9
SE = sqrt(.9 * (1 - .9)/num_samples)
# Code for calculation of z and one sided p value
z = (observed - expected)/SE
pval = pnorm(z)
# Print p value
pval
num_flips = 30
num_heads = 12
p = num_heads/num_flips
se = sqrt(p * (1 - p) / num_flips)
c(p-1.96*se, p+1.96*se)
num_flips = 30
num_heads = 21
p = num_heads/num_flips
se = sqrt(p * (1 - p) / num_flips)
c(p-1.96*se, p+1.96*se)
in_conf_int = numeric(10000)
for(i in 1:10000){
num_flips = 30
num_heads = rbinom(1, 30, prob = 0.5)
p = num_heads/num_flips
se = sqrt(p * (1 - p) / num_flips)
in_conf_int[i] = 0.5 >= (p-1.96*se) & 0.5 <= (p+1.96*se)
}
mean(in_conf_int)
barplot(table(in_conf_int)/10000, main = "Confidence Interval contains 0.5")
qt(97.5, 29)
qt(0.975, 29)
qt(0.025, 29)
c(65.02 - 2.04523 * 51.42, 65.02 + 2.04523 * 51.42)
c(65.02 - 2.04523 * 51.42/sqrt(30), 65.02 + 2.04523 * 51.42/sqrt(30))
# Helper Functions
sigmoid = function(x){1/(1+exp(-x))}
bernoulli_sampler = function(n, p){as.integer(runif(n) < p)}
intToBin = function(t, d){
if (t == 0){res = c(0)}
res = c()
while (t > 1){
res = c(t %% 2, res)
t = t %/% 2
}
if (t == 1){res = c(t, res)}
if (length(res) < d){res = c(rep(0, d-length(res)), res)}
return(paste(res, collapse=""))
}
my_lambda = function(xi){
ans = rep(1/8, length(xi))
ans[xi != 0] = (sigmoid(xi[xi != 0])-1/2)/(2*xi[xi != 0])
ans
}
trace = function(M){sum(diag(M))}
my_lbeta = function(x){sum(lgamma(x))-lgamma(sum(x))}
generate_beta = function(d){
if (d == 1){
beta = c(runif(1,-1.15,-1.05))
}else if (d == 2){
beta = c(runif(1,-1.15,-1.05), runif(1, 2.9, 3.1))
}else if (d == 4){
beta = c(runif(1,-1.15,-1.05), runif(2, 1.45, 1.55), runif(1, 0.45, 0.55))
}else if (d == 8){
beta = c(runif(1,-1.15,-1.05), runif(2, 0.65, 0.75), runif(1, 0.55, 0.65), runif(1, 0.65, 0.75), runif(2, 0.55, 0.65), runif(1, 0.35, 0.45))
}else if (d == 16){
beta = c(runif(1, -2.02, -1.99), runif(2, 0.68, 0.72), runif(1, 0.23, 0.27), runif(1, 0.68, 0.72), runif(2, 0.23, 0.27), runif(1, 0.18, 0.22), runif(1, 0.68, 0.72),
runif(2, 0.23, 0.27), runif(1, 0.23, 0.27), runif(1, 0.68, 0.72), runif(2, 0.23, 0.27), runif(1, 0.13, 0.17))
}
beta
}
generate_delta_matrix = function(Q, k){
calculate_q = function(t, q){prod(sapply(1:length(q), function(i){ifelse(substr(t,i,i) == '1', q[i], 1)}))}
calculate_delta = function(q){
t = sapply(0:(2^k-1), function(i){intToBin(i, d = k)})
Q_res = matrix(rep(sapply(t, function(x){calculate_q(x, q)}), 2^k), ncol = 2^k, byrow = T, dimnames = list(t,t))
A_res = matrix(unlist(lapply(t, function(y){sapply(t, function(x){calculate_q(x, sapply(1:k, function(i){as.numeric(substr(y,i,i))}))})})), ncol = 2^k, byrow = T, dimnames = list(t,t))
A_res*Q_res
}
lapply(1:nrow(Q), function(i){calculate_delta(Q[i,])})
}
plot_ccr = function(res, data){
k = dim(data$Q)[2]
N = length(data$skill)
post_pred = sapply(1:N, function(i)which.max(res$p_matrix[i,]))
post_pred = sapply(post_pred, function(i){intToBin(i-1, d = k)})
res = c()
cnames = c()
for (i in 1:k){
res = c(res, sum(sapply(1:N, function(n) substr(data$skill[n],i,i) == substr(post_pred[n],i,i)))/N)
cnames = c(cnames, paste("CCR", as.character(i)))
}
df = data.frame(c(res, sum(data$skill == post_pred)/N), c(cnames, 'CCRAll'))
colnames(df) = c("Ratio", "names")
ggplot(df, aes(x = names,  y =Ratio))+
geom_point()+
theme(axis.title.x=element_blank(),
axis.ticks.x=element_blank(),
panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.minor.y = element_blank())
}
plot_ELBO = function(res, data){
temp = data.frame(1:length(res$ELBO), res$ELBO)
colnames(temp) = c("Iteration", "ELBO")
ggplot(temp, aes(x = Iteration, y = ELBO))+
geom_point()+
geom_line()+
theme(axis.ticks.x=element_blank(),
axis.ticks.y=element_blank(),
panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.minor.y = element_blank()
)
}
label_beta = function(d, k){
res = c()
for (i in 1:d){
res = c(res, paste0(sum(as.integer(unlist(strsplit(intToBin(i-1,k),"")))), "-way interaction"))
}
res[res == "0-way interaction"] = "Intercept"
res[res == "1-way interaction"] = "Main effect"
res
}
# Data Simulation
data_generate = function(N, k, J, seed = 1){
set.seed(seed)
col_name = sapply(0:(2^k-1), function(i){intToBin(i, d = k)})
prob = rep(1/2^k, 2^k) #1:2^k/sum(2^k)
skills = sapply(sample(0:(2^k-1), N, replace = T, prob = prob), function(x){intToBin(x, k)})
Q_matrix = sapply(sample(0:(2^k-1), J, replace = T), function(x){intToBin(x, k)})
Q_matrix = t(sapply(Q_matrix, function(x){sapply(1:k, function(i){as.numeric(substr(x,i,i))})}))
rownames(Q_matrix) = 1:J
beta = lapply(1:J, function(j) generate_beta(2^sum(Q_matrix[j,])))
delta_matrix = generate_delta_matrix(Q_matrix, k)
valid_cols = lapply(1:J, function(j) names(which(colSums(delta_matrix[[j]])>0)))
for (j in 1:J){
delta_matrix[[j]] = matrix(delta_matrix[[j]][,valid_cols[[j]]], nrow = 2^k, dimnames = c(list(rownames(delta_matrix[[1]])), list(valid_cols[[j]])))
}
simulate_once = function(j, beta, delta_matrix){
samples = bernoulli_sampler(length(skills), as.vector(sigmoid(delta_matrix[[j]][skills,]%*%beta[[j]])))
return(samples)
}
Y = sapply(1:J, function(j) bernoulli_sampler(length(skills), as.vector(sigmoid(matrix(delta_matrix[[j]][skills,], nrow = N)%*%beta[[j]]))))
return (list('Y' = Y, 'Q' = Q_matrix, 'skill' = skills, 'beta' = beta, 'delta_matrix' = delta_matrix))
}
# Main Algorithm
JJVI_fit = function(data, max_iter = 500, tolerance = 1e-10){
N = dim(data$Y)[1]
J = dim(data$Y)[2]
k = dim(data$Q)[2]
L = 2^k
dim_beta = sapply(1:J, function(j) length(data$beta[[j]]))
a0 = rep(1e-2, J)
b0 = rep(1e-4, J)
d0 = rep(1, L)
xi = matrix(rep(0, J*L), ncol = L, byrow = T)
max_iter = 500
E_Z = matrix(rep(1/L, L*N), ncol = L)
# First Iteration
inv_V = lapply(1:J, function(j) 2*t(data$delta_matrix[[j]])%*%diag(my_lambda(xi[j,])*colSums(E_Z))%*%data$delta_matrix[[j]]+a0[j]/b0[j]*diag(dim_beta[j]))
V = lapply(inv_V, solve)
mu = lapply(1:J, function(j)V[[j]]%*%t(data$delta_matrix[[j]])%*%t(E_Z)%*%(data$Y[,j]-1/2))
E_tbeta_beta = sapply(1:J, function(j) t(mu[[j]])%*%mu[[j]]+trace(V[[j]]))
a = a0 + dim_beta/2
b = b0 + E_tbeta_beta/2
d = d0 + colSums(E_Z)
calculate_ELBO = function(a,b,d,E_Z,mu,V){
term1 = sum(colSums(E_Z)*(rowSums(sapply(1:J, function(j) -diag(data$delta_matrix[[j]]%*%(mu[[j]]%*%t(mu[[j]])+V[[j]])%*%t(data$delta_matrix[[j]]))*my_lambda(xi[j,])))+colSums(apply(xi, c(1,2), function(x){log(sigmoid(x))-x/2+my_lambda(x)*x^2}))))+sum(sapply(1:J, function(j) t(mu[[j]])%*%t(data$delta_matrix[[j]])%*%t(E_Z)%*%(data$Y[,j]-1/2)))
term2 = sum(sapply(1:N, function(i) sum(sapply(1:L, function(l) E_Z[i,l]*(digamma(d[l])-digamma(sum(d))-log(E_Z[i,l]))))))
term3 = sum((d0-d)*(digamma(d)-digamma(sum(d))))+my_lbeta(d)-my_lbeta(d0)
term4 = -1/2*sum(sapply(1:J, function(j){(t(mu[[j]])%*%mu[[j]]+trace(V[[j]]))*a[j]/b[j]}))
term5 = 1/2*sum(sapply(V, function(M){log(abs(det(M)))}))
return (term1+term2+term3+term4+term5+sum(lgamma(a))+sum(a*(1-b0/b))-sum(a*log(b)))
}
ELBO_arr = c(calculate_ELBO(a,b,d,E_Z,mu,V))
for (iter_ in 1:max_iter){
E_beta_tbeta = lapply(1:J, function(j){V[[j]]+mu[[j]]%*%t(mu[[j]])})
xi = t(sapply(1:J, function(j) sqrt(diag(data$delta_matrix[[j]]%*%E_beta_tbeta[[j]]%*%t(data$delta_matrix[[j]])))))
# Update Q_1
E_log_pi = digamma(d)-digamma(sum(d))
E_Z = matrix(rep(colSums(apply(xi, c(1,2), function(x){log(sigmoid(x))-x/2+my_lambda(x)*x^2}))+ E_log_pi + rowSums(sapply(1:J, function(j) -diag(data$delta_matrix[[j]]%*%(mu[[j]]%*%t(mu[[j]])+V[[j]])%*%t(data$delta_matrix[[j]]))*my_lambda(xi[j,]))) , N), nrow = N, byrow=T)+Reduce("+", lapply(1:J, function(j) (data$Y[,j]-1/2)%*%t(mu[[j]])%*%t(data$delta_matrix[[j]])))
E_Z = t(apply(E_Z, 1, function(x)exp(x-max(x))/sum(exp(x-max(x)))))
# Update Q_2
inv_V = lapply(1:J, function(j) 2*t(data$delta_matrix[[j]])%*%diag(my_lambda(xi[j,])*colSums(E_Z))%*%data$delta_matrix[[j]]+a[j]/b[j]*diag(dim_beta[j]))
V = lapply(inv_V, solve)
mu = lapply(1:J, function(j) V[[j]]%*%t(data$delta_matrix[[j]])%*%t(E_Z)%*%(data$Y[,j]-1/2))
# Update Q_3
d = d0 + colSums(E_Z)
# Q4
E_tbeta_beta = sapply(1:J, function(j){(t(mu[[j]])%*%mu[[j]])+trace(V[[j]])})
b = b0 + E_tbeta_beta/2
ELBO = calculate_ELBO(a,b,d,E_Z,mu,V)
if ((ELBO > ELBO_arr[length(ELBO)]) &abs(ELBO-ELBO_arr[length(ELBO_arr)])<abs(tolerance*ELBO_arr[length(ELBO)])){
break
}else{ELBO_arr = c(ELBO_arr, ELBO)}
}
beta_sd = lapply(1:J, function(j)sqrt(diag(V[[j]])))
res = list('beta_mu_post' = mu, 'beta_sd_post' = beta_sd, 'delta_matrix' = data$delta_matrix, 'ELBO' = ELBO_arr, 'p_matrix' = E_Z, 'xi' = xi, 'd' = d)
p1 = plot_ELBO(res, data)
df = data.frame(cbind(unlist(res$beta_mu_post), unlist(res$beta_sd_post), unlist(data$beta)), unlist(lapply(1:length(res$beta_mu_post), function(j) label_beta(length(res$beta_mu_post[[j]]), dim(data$Q)[2]))),
row.names = 1: length(unlist(data$beta)))
colnames(df) = c("posterior mean", "posterior sd", "true value", "Type")
df['lower'] = df$`posterior mean`- qnorm(0.975)*df$`posterior sd`
df['upper'] = df$`posterior mean`+ qnorm(0.975)*df$`posterior sd`
df['index'] = 1:nrow(df)
p2 = ggplot(df, aes(x = index, y = `posterior mean`))+geom_errorbar(aes(ymin = lower, ymax = upper))+geom_point(aes(y = `true value`, col = Type))
p3 = ggplot(df, aes(x =`true value`, y=`posterior mean`, col = Type))+geom_point()+geom_abline(slope = 1)
p4 = plot_ccr(res, data)
theme_set(theme_pubr())
p_final = ggarrange(p1, p2, p3, p4 , ncol = 2, nrow = 2)
ggsave("fig", plot = p_final, device = "eps", width = 20, height = 12, dpi = 320)
res$`fig` = p_final
res$`recovery rate` = sum((df$lower-df$`true value`)*(df$upper-df$`true value`) <= 0)/nrow(df)
return(res)
}
load("data.RData")
getwd()
setwd("C:/Users/14842/Desktop/BBVI project/DCM_model")
getwd()
load("data.RData")
load("res.RData")
View(res)
View(res)
knitr::opts_chunk$set(echo = TRUE)
qnorm(.975)
qt(.975, df = 767 - 1)
qt(.975, df = 10000)
qt(.975, df = 767 - 1)
qt(.975, df = 30)
qt(.975, df = 100)
qt(.975, df = 766)
# Fill in the observed proportion of respondents that claim they give more emotional support than they receive
p_hat = .44
# Calculate the standard error
SE = sqrt(.44 * (1 - .44)/767)
# Assign the variable z or t with the value corresponding to a 99 percent confidence interval
z = qnorm(.995)
# Calculate the margin of error
ME =  z * SE
# Print out the confidence interval
c(p_hat - ME, p_hat + ME)
# Calculate the margin of error
ME =  t * SE
# Fill in the observed proportion of respondents that claim they give more emotional support than they receive
p_hat = .44
# Calculate the standard error
SE = sqrt(.44 * (1 - .44)/767)
# Assign the variable z or t with the value corresponding to a 99 percent confidence interval
z = qnorm(.995)
t = qt(.995, df = 767 - 1)
# Calculate the margin of error
ME =  t * SE
# Print out the confidence interval
c(p_hat - ME, p_hat + ME)
# Fill in the observed proportion of respondents that claim they give more emotional support than they receive
p_hat = .44
# Calculate the standard error
SE = sqrt(.44 * (1 - .44)/767)
# Assign the variable z or t with the value corresponding to a 99 percent confidence interval
z = qnorm(.995)
t = qt(.995, df = 767 - 1)
# Calculate the margin of error
ME =  z * SE
# Print out the confidence interval
c(p_hat - ME, p_hat + ME)
# Calucate the margin of error of the survey you didn't choose in part a
SE_1 = sqrt(.96 * (1 - .96)/4500)
ME_1 = z * SE_1
# Calcuate how many more samples are needed to make the two margin of errors similar to each other
# Fill in the observed proportion of respondents that claim they give more emotional support than they receive
p_hat = .44
# Calculate the standard error
SE = sqrt(.44 * (1 - .44)/767)
# Assign the variable z or t with the value corresponding to a 99 percent confidence interval
z = qnorm(.995)
t = qt(.995, df = 767 - 1)
# Calculate the margin of error
ME_2 =  z * SE
# Print out the confidence interval
c(p_hat - ME, p_hat + ME)
# Calucate the margin of error of the survey you didn't choose in part a
SE_1 = sqrt(.96 * (1 - .96)/4500)
ME_1 = z * SE_1
# Calcuate how many more samples are needed to make the two margin of errors similar to each other
ME_2 / ME_1
# Calucate the margin of error of the survey you didn't choose in part a
SE_1 = sqrt(.96 * (1 - .96)/4500)
ME_1 = z * SE_1
# Calcuate how many more samples are needed to make the two margin of errors similar to each other
ME_2 / ME_1
767 * (6.135689)^2
setwd("C:/Users/14842/Desktop/ucla-stats-13")
marriage_age_diff = read.table("MarriageAgesDiff.txt", header = TRUE)
stripchart(marriage_age_diff, method = "stack")
getwd()
library(ggplot2)
ggplot(data = marriage_age_diff, aes(x = Diff.H.W.)) + geom_dotplot() + ylim(0, 10)
ggplot(data = marriage_age_diff, aes(x = Diff.H.W.)) + geom_dotplot()
ggplot(data = marriage_age_diff, aes(x = Diff.H.W.)) + geom_dotplot() + ylim(0, 10)
ggplot(data = marriage_age_diff, aes(x = Diff.H.W.)) + geom_dotplot() + ylim(0, 20)
setwd("C:/Users/14842/Desktop/ucla-stats-13")
# Create a dataframe/tibble that reports 100,000
# responses to the question:
# "Do you believe that the work scientists do benefit people like you?"
global_monitor <- tibble(
scientist_work = c(rep("Benefits", 80000), rep("Doesn't benefit", 20000))
)
# Load the tidyverse, openintro and infer packages, or libraries.
library(tidyverse)
library(openintro)
library(infer)
# If any of these do not work since you do not have them installed yet, run
# install.packages('infer') in console
# install.packages(infer) -> installs 'infer' package on pc forever
# library(infer) -> tells file you want to use packages from the 'infer' package
# (replace infer with other package name if needed)
# Setting a seed -> makes it such that every time you call a random
# function, it returns the same result (helpful for testing purposes)
set.seed(42)
sample.int(n = 100, size = 1) # 49
set.seed(42)
sample.int(n = 100, size = 1) # same result
# Load the tidyverse, openintro and infer packages, or libraries.
library(tidyverse)
library(openintro)
library(infer)
# If any of these do not work since you do not have them installed yet, run
# install.packages('infer') in console
# install.packages(infer) -> installs 'infer' package on pc forever
# library(infer) -> tells file you want to use packages from the 'infer' package
# (replace infer with other package name if needed)
# Setting a seed -> makes it such that every time you call a random
# function, it returns the same result (helpful for testing purposes)
set.seed(42)
sample.int(n = 100, size = 1) # 49
set.seed(42)
sample.int(n = 100, size = 1) # same result
# Create a dataframe/tibble that reports 100,000
# responses to the question:
# "Do you believe that the work scientists do benefit people like you?"
global_monitor <- tibble(
scientist_work = c(rep("Benefits", 80000), rep("Doesn't benefit", 20000))
)
# Create a bar plot of global_monitor
ggplot(global_monitor, aes(x = scientist_work)) +
geom_bar() +
labs(
x = "", y = "",
title = "Do you believe that the work scientists do benefit people like you?"
) +
coord_flip()
# Calculate the proportion of each response
global_monitor %>%
count(scientist_work) %>%
mutate(p = n /sum(n))
# Set the seed to 42
set.seed(42)
# Sample 50 responses
samp1 <- global_monitor %>%
sample_n(50)
### Create a bar plot of your sample
### Calculate the proportion of each response in your sample
=======
pt(.975, df = 30)
qt(.975, df = 30)
qt(.975, df = 300)
qt(.975, df = 3000)
setwd("C:/Users/Dan Chen/Desktop/ucla-stats-13")
read.table("MarriageAgesDiff.txt", header = TRUE)
knitr::opts_chunk$set(echo = TRUE)
dotchart(read.table("MarriageAgesDiff.txt", header = TRUE))
dotchart(read.table("MarriageAgesDiff.txt", header = TRUE)[,1])
library(ggplot)
install.packages("tidyverse")
stripchart(read.table("MarriageAgesDiff.txt", header = TRUE))
stripchart(read.table("MarriageAgesDiff.txt", header = TRUE), method = "stack")
library(ggplot2)
marriage_age_diff = read.table("MarriageAgesDiff.txt", header = TRUE)
ggplot(data = marriage_age_diff, aes(x = Diff.H.W.)) + geom_dotplot()
library(ggplot2)
ggplot(data = marriage_age_diff, aes(x = Diff.H.W.)) + geom_dotplot()
ggplot(data = marriage_age_diff, aes(x = Diff.H.W.)) + geom_dotplot() + ylim(0, 2)
library(ggplot2)
ggplot(data = marriage_age_diff, aes(x = Diff.H.W.)) + geom_dotplot() + ylim(0, 2)
ggplot(data = marriage_age_diff, aes(x = Diff.H.W.)) + geom_dotplot() + ylim(0, 4)
ggplot(data = marriage_age_diff, aes(x = Diff.H.W.)) + geom_dotplot() + ylim(0, 10)
>>>>>>> d63dde88ca8d6ea97dc31e5a7da5124c5faaed4e
